---
title: "wrangling"
author: "Luiz Felipe"
date: "`r Sys.Date()`"
output: html_document
---

```{r}
library(readxl)
library(tidyverse)
```

```{r}
file_paths <- list(
  aqua = "sensor/24 KSU TAPS AquaSpy.xlsx",
  arable = "sensor/24 KSU TAPS Arable.xlsx",
  cropx = "sensor/24 KSU TAPS CropX.xlsx",
  groguru = "sensor/24 KSU TAPS GroGuru.xlsx",
  sentek = "sensor/24 KSU TAPS Sentek.xlsx"
)

read_and_bind_sheets_in_file <- function(file_path) {
  sheets <- excel_sheets(file_path)
  
  map_dfr(sheets, ~ read_excel(file_path, sheet = .x) %>%
            mutate(sheet_name = .x))
}

df_aqua <- read_and_bind_sheets_in_file(file_paths$aqua)[1:6]
#df_arable <- read_and_bind_sheets_in_file(file_paths$arable)
#df_cropx <- read_and_bind_sheets_in_file(file_paths$cropx)
#df_groguru <- read_and_bind_sheets_in_file(file_paths$groguru)
df_sentek <- read_and_bind_sheets_in_file(file_paths$sentek)

df_aqua %>% 
  summarise(Team, Timestamp, moist_6inch = (`4"...4`+`8"...5`)/2) %>% 
  mutate(Date = as.Date(Timestamp)) %>%  
  group_by(Team, Date) %>%               
  summarise(daily_avg_moist = mean(moist_6inch, na.rm = TRUE), .groups = "drop") %>% 
  mutate(sensor = "aqua") %>% 
  
  bind_rows(

df_sentek %>% 
  summarise(Team, Timestamp, moist_6inch = `Sensor #2 (15 cm)`) %>% 
  mutate(Date = as.Date(Timestamp)) %>%  
  group_by(Team, Date) %>%               
  summarise(daily_avg_moist = mean(moist_6inch, na.rm = TRUE), .groups = "drop") %>% 
  mutate(sensor = "sentek")

  ) %>% 
  
  write.csv(file = "soil_aqua_sentek_6inch.csv")
```

# Model training

## Wrangling

```{r}
df.xgb <- read.csv(file = "weather_data_joined_team.csv") %>% 
  mutate(date = as.Date(date))
  
df.xgb <- df.xgb %>% 
  summarise(date,
            et0_mm = arable_field_evapotranspiration_mm,               # Reference Evapotranspiration (ET0, mm)
            etc_mm = arable_canopy_evapotranspiration_mm,              # Crop Evapotranspiration (ETc, mm)
            gdd_daily_c = growing_degree_days,                         # Daily Growing Degree Days (°C)
            gdd_cumulative_c = accumulated_growing_degree_days,        # Cumulative Growing Degree Days (°C)
            ndvi,                                                      # Normalized Difference Vegetation Index
            rh_min_perc = minimum_relative_humidity,                   # Minimum Relative Humidity (%)
            rh_at_tmax_perc = relative_humidity_at_max_temp,           # Relative Humidity at Max Temperature (%)
            rh_at_tmin_perc = relative_humidity_at_min_temp,           # Relative Humidity at Min Temperature (%)
            sw_radiation_wm2 = shortwave_downwelling_radiation,        # Shortwave Downwelling Radiation (W/m²)
            temp_max_c = max_temp,                                     # Maximum Temperature (°C)
            temp_min_c = min_temp,                                     # Minimum Temperature (°C)
            temp_mean_c = mean_temp,                                   # Mean Temperature (°C)
            dew_point_max_c = max_dew_point_temp,                      # Maximum Dew Point Temperature (°C)
            precip_mm = precipitation,                                 # Precipitation (mm)
            precip_hours = precipitation_hours,                        # Precipitation Duration (hours)
            precip_cumulative_mm = cumulative_precipitation,           # Cumulative Precipitation (mm)
            slp_hpa = sea_level_pressure,                              # Sea Level Pressure (hPa)
            vpd_hpa = vapor_pressure_deficit,                          # Vapor Pressure Deficit (hPa)
            kc = crop_coefficient,                                     # Crop Coefficient (Kc, unitless)
            dew_temp_c = dew_temp,                                     # Dew Temperature (°C)
            crop_water_demand_mm_day,                                  # Crop Water Demand (mm/day)
            sun_duration_hours = sun_duration,                         # Sunlight Duration (hours)
            wind_speed_mps = wind_speed,                               # Wind Speed (m/s)
            wind_dir_deg = wind_direction_degrees,                     # Wind Direction (degrees)
            wind_speed_max_mps = max_wind_speed,                       # Maximum Wind Speed (m/s)
            wind_speed_min_mps = min_wind_speed,                       # Minimum Wind Speed (m/s)
            trt_id = TrtID) %>% 
  drop_na()

summary(df.xgb)
```

# Model: ETc 

```{r}
# Generate a 70-30 split for treatments, preserving the structure within each treatment
train_treatments <- df.xgb %>%
  group_by(trt_id) %>%
  summarise() %>%
  sample_frac(0.7) %>%
  pull(trt_id)

# Divide dataset into training and test based on treatment IDs
df_train <- df.xgb %>%
  filter(trt_id %in% train_treatments)

df_test <- df.xgb %>%
  filter(!trt_id %in% train_treatments)
```

```{r}
# Prepare training data for NDVI prediction
X_train <- df_train %>%
  dplyr::select(-c(trt_id, date, ndvi)) %>%
  as.matrix()

y_train <- df_train$ndvi

# Hyperparameter tuning using k-fold cross-validation
ndvi_model <- caret::train(
  x = X_train,
  y = y_train,
  trControl = tune_control,
  tuneGrid = hyperparam_grid,
  method = "xgbTree",
  verbose = FALSE,
  verbosity = 0)

# Extract best hyperparameters
best_params_ndvi <- ndvi_model$bestTune

# Initialize the result data frame for NDVI predictions, including trt_id and date
ndvi_preds_final <- data.frame(trt_id = integer(), date = as.Date(character()), preds = numeric(), observed_ndvi = numeric())

# Initialize an empty list for variable importance
ndvi_importance_list <- list()

# Unique treatments for Leave-One-Treatment-Out Cross-Validation
unique_treatments <- unique(df.xgb$trt_id)

for (trt in unique_treatments) {
  
  # Define training and test set for the current treatment
  df_train_loocv <- df.xgb %>% filter(trt_id != trt)
  df_test_loocv <- df.xgb %>% filter(trt_id == trt)
  
  # Prepare data matrices
  X_train_loocv <- df_train_loocv %>% dplyr::select(-c(trt_id, date, ndvi)) %>% as.matrix()
  y_train_loocv <- df_train_loocv$ndvi
  
  X_test_loocv <- df_test_loocv %>% dplyr::select(-c(trt_id, date, ndvi)) %>% as.matrix()
  y_test_loocv <- df_test_loocv$ndvi
  
  # Train model using best parameters
  final_ndvi_model <- xgboost(
    data = X_train_loocv,
    label = y_train_loocv,
    booster = "gbtree",
    objective = "reg:squarederror",
    nrounds = best_params_ndvi$nrounds,
    max_depth = best_params_ndvi$max_depth,
    colsample_bytree = best_params_ndvi$colsample_bytree,
    min_child_weight = best_params_ndvi$min_child_weight,
    subsample = best_params_ndvi$subsample,
    eta = best_params_ndvi$eta,
    gamma = best_params_ndvi$gamma,
    verbose = 0)
  
  # Make predictions for the left-out treatment
  temp_pred_ndvi <- predict(final_ndvi_model, X_test_loocv)
  
  # Store predictions and actual NDVI values with trt_id and date
  preds <- data.frame(trt_id = trt, date = df_test_loocv$date, preds = temp_pred_ndvi, observed_ndvi = y_test_loocv)
  
  # Combine predictions for evaluation
  ndvi_preds_final <- rbind(ndvi_preds_final, preds)
  
  # Extract variable importance if desired
  importance <- xgb.importance(model = final_ndvi_model)
  importance$iteration <- trt
  ndvi_importance_list[[as.character(trt)]] <- importance
}

# Optional: Evaluate model performance for NDVI
ndvi_rmse <- rmse(ndvi_preds_final$observed_ndvi, ndvi_preds_final$preds)
ndvi_mae <- mae(ndvi_preds_final$observed_ndvi, ndvi_preds_final$preds)
ndvi_r2 <- cor(ndvi_preds_final$observed_ndvi, ndvi_preds_final$preds)^2

list(NDVI_RMSE = ndvi_rmse, NDVI_MAE = ndvi_mae, NDVI_R_squared = ndvi_r2)
```

```{r}
# Variable importance
ndvi_importance_df <- do.call(rbind, ndvi_importance_list) %>%
  group_by(Feature) %>%
  summarise(Importance = mean(Gain, na.rm = TRUE)) %>%
  arrange(desc(Importance))

top_10_ndvi <- ndvi_importance_df %>% top_n(15, Importance)

# Create a variable importance plot for the top 10 variables
ggplot(top_10_ndvi, aes(x = reorder(Feature, Importance), y = Importance, fill = Importance)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  coord_flip() +
  scale_fill_gradient(low = "grey", high = "purple") +
  labs(title = "Variable Importance for NDVI Prediction (Top 15)",
       x = "Features",
       y = "Gain") +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 20),
    axis.title.x = element_text(face = "bold", size = 15),
    axis.title.y = element_text(face = "bold", size = 15),
    axis.text = element_text(size = 12))

# Scatter plot with metrics display for NDVI predictions
ndvi_preds_final <- ndvi_preds_final %>% na.omit()

# Calculate metrics for NDVI predictions
ndvi_r_squared <- cor(ndvi_preds_final$observed_ndvi, ndvi_preds_final$preds)^2
ndvi_mae <- mean(abs(ndvi_preds_final$observed_ndvi - ndvi_preds_final$preds))
ndvi_rmse <- sqrt(mean((ndvi_preds_final$observed_ndvi - ndvi_preds_final$preds)^2))
ndvi_rrmse <- ndvi_rmse / mean(ndvi_preds_final$observed_ndvi) * 100
ndvi_kge <- 1 - sqrt((ndvi_r_squared - 1)^2 + (mean(ndvi_preds_final$preds) / mean(ndvi_preds_final$observed_ndvi) - 1)^2)

# Scatter plot for observed vs. predicted NDVI with metrics
ggplot(ndvi_preds_final, aes(x = observed_ndvi, y = preds)) +
  geom_point(shape = 21, color = "grey", fill = "steelblue", alpha = 0.5, size = 3) +
  geom_abline(slope = 1, intercept = 0, color = "black", size = 1) + # 1:1 line
  xlim(0, 1) +
  ylim(0, 1) +
  theme_bw() +
  labs(x = "Observed NDVI", y = "Predicted NDVI") +
  # Add metrics as text
  annotate("text", x = 0.1, y = 1, 
           label = paste0(
             "R²: ", round(ndvi_r_squared, 3), "\n",
             "MAE: ", round(ndvi_mae, 3), "\n",
             "RMSE: ", round(ndvi_rmse, 3), "\n",
             "RRMSE: ", round(ndvi_rrmse, 1), "%\n",
             "KGE: ", round(ndvi_kge, 3)
           ), hjust = 0, vjust = 1) +
  theme(aspect.ratio = 1,
        text = element_text(size = 18))
```


```{r}
# Variable importance
importance_df <- do.call(rbind, importance_list_) %>%
  group_by(Feature) %>%
  summarise(Importance = mean(Gain, na.rm = TRUE)) %>%
  arrange(desc(Importance))

top_10 <- importance_df %>% top_n(15, Importance)

# Create a variable importance plot for the top 10 variables
ggplot(top_10, aes(x = reorder(Feature, Importance), y = Importance, fill = Importance)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  coord_flip() +
  scale_fill_gradient(low = "grey", high = "purple") +
  labs(title = "Variable Importance (Top 10)",
       x = "Features",
       y = "Gain") +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 20),
    axis.title.x = element_text(face = "bold", size = 15),
    axis.title.y = element_text(face = "bold", size = 15),
    axis.text = element_text(size = 12))
```

```{r}
preds_final <- preds_final %>% na.omit()

# Calculate metrics
r_squared <- cor(preds_final$etc_mm, preds_final$preds)^2
mae <- mean(abs(preds_final$etc_mm - preds_final$preds))
rmse <- sqrt(mean((preds_final$etc_mm - preds_final$preds)^2))
rrmse <- rmse / mean(preds_final$etc_mm) * 100
kge <- 1 - sqrt((r_squared - 1)^2 + (mean(preds_final$preds) / mean(preds_final$etc_mm) - 1)^2)

# Scatter plot with regression line and metrics
ggplot(preds_final, aes(x = etc_mm, y = preds)) +
  geom_point(shape = 21, color = "grey", fill = "steelblue", alpha = 0.5, size = 3) +
  geom_abline(slope = 1, intercept = 0, color = "black", size = 1) + # 1:1 line
  xlim(0, 0.4) +
  ylim(0, 0.4) +
  theme_bw() +
  labs(x = "Observed ETc (mm/day)", y = "Predicted ETc (mm/day)") +
  # Add metrics as text
  annotate("text", x = 0.0025, y = 0.4, 
           label = paste0(
             "R²: ", round(r_squared, 3), "\n",
             "MAE: ", round(mae, 3), "\n",
             "RMSE: ", round(rmse, 3), "\n",
             "RRMSE: ", round(rrmse, 1), "%\n",
             "KGE: ", round(kge, 3)
           ), hjust = 0, vjust = 1) +
  theme(aspect.ratio = 1,
        text = element_text(size = 18))
```

# Model: NDVI 

```{r}
df.xgb2 <- df.xgb %>%
  arrange(trt_id, date) %>% 
  group_by(trt_id) %>%
  mutate(ndvi_day_before = lag(ndvi), .after = ndvi) %>% 
  ungroup() %>% drop_na() %>% select(-kc)
```

```{r}
# Generate a 70-30 split for treatments, preserving the structure within each treatment
train_treatments <- df.xgb2 %>%
  group_by(trt_id) %>%
  summarise() %>%
  sample_frac(0.7) %>%
  pull(trt_id)

# Divide dataset into training and test based on treatment IDs
df_train <- df.xgb2 %>%
  filter(trt_id %in% train_treatments)

df_test <- df.xgb2 %>%
  filter(!trt_id %in% train_treatments)
```

```{r}
tune_control <- caret::trainControl(
  method = "cv",
  number = 5,
  verboseIter = FALSE,
  allowParallel = TRUE)

# Hyperparameter grid
hyperparam_grid <- expand.grid(
  nrounds = c(50, 200, 300),
  max_depth = c(2, 3, 5, 8, 10),
  eta = c(0.005, 0.01, 0.1),
  gamma = 0,
  colsample_bytree = c(0.7, 1),
  min_child_weight = 1,
  subsample = c(0.5, 0.7, 1))

# Prepare training data for NDVI prediction
X_train <- df_train %>%
  dplyr::select(-c(trt_id, date, ndvi)) %>%
  as.matrix()

y_train <- df_train$ndvi

# Hyperparameter tuning using k-fold cross-validation
bst <- caret::train(
  x = X_train,
  y = y_train,
  trControl = tune_control,
  tuneGrid = hyperparam_grid,
  method = "xgbTree",
  verbose = FALSE,
  verbosity = 0)

# Extract best hyperparameters
best_params <- bst$bestTune

# Initialize the result data frame for NDVI predictions, including trt_id and date
preds_final <- data.frame(trt_id = integer(), date = as.Date(character()), preds = numeric(), observed_ndvi = numeric())

# Initialize an empty list for variable importance
importance_list_ <- list()

# Unique treatments for Leave-One-Treatment-Out Cross-Validation
unique_treatments <- unique(df.xgb2$trt_id)

for (trt in unique_treatments) {
  
  # Define training and test set for the current treatment
  df_train_loocv <- df.xgb2 %>% filter(trt_id != trt)
  df_test_loocv <- df.xgb2 %>% filter(trt_id == trt)
  
  # Prepare data matrices
  X_train_loocv <- df_train_loocv %>% dplyr::select(-c(trt_id, date, ndvi)) %>% as.matrix()
  y_train_loocv <- df_train_loocv$ndvi
  
  X_test_loocv <- df_test_loocv %>% dplyr::select(-c(trt_id, date, ndvi)) %>% as.matrix()
  y_test_loocv <- df_test_loocv$ndvi
  
  # Train model using best parameters
  final_model <- xgboost(
    data = X_train_loocv,
    label = y_train_loocv,
    booster = "gbtree",
    objective = "reg:squarederror",
    nrounds = best_params$nrounds,
    max_depth = best_params$max_depth,
    colsample_bytree = best_params$colsample_bytree,
    min_child_weight = best_params$min_child_weight,
    subsample = best_params$subsample,
    eta = best_params$eta,
    gamma = best_params$gamma,
    verbose = 0
  )
  
  # Make predictions for the left-out treatment
  temp_pred <- predict(final_model, X_test_loocv)
  
  # Store predictions and actual NDVI values with trt_id and date
  preds <- data.frame(trt_id = trt, date = df_test_loocv$date, preds = temp_pred, observed_ndvi = y_test_loocv)
  
  # Combine predictions for evaluation
  preds_final <- rbind(preds_final, preds)
  
  # Extract variable importance if desired
  importance <- xgb.importance(model = final_model)
  importance$iteration <- trt
  importance_list_[[as.character(trt)]] <- importance
}

# Optional: Evaluate model performance for NDVI
rmse_score <- rmse(preds_final$observed_ndvi, preds_final$preds)
mae_score <- mae(preds_final$observed_ndvi, preds_final$preds)
r2_score <- cor(preds_final$observed_ndvi, preds_final$preds)^2

list(NDVI_RMSE = rmse_score, NDVI_MAE = mae_score, NDVI_R_squared = r2_score)
```

```{r}
importance_df <- do.call(rbind, importance_list_) %>%
  group_by(Feature) %>%
  summarise(Importance = mean(Gain, na.rm = TRUE)) %>%
  arrange(desc(Importance))

top_10 <- importance_df %>% top_n(15, Importance)

# Create a variable importance plot for the top 10 variables
ggplot(top_10, aes(x = reorder(Feature, Importance), y = Importance, fill = Importance)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  coord_flip() +
  scale_fill_gradient(low = "grey", high = "purple") +
  labs(title = "Variable Importance for NDVI (Top 15)",
       x = "Features",
       y = "Gain") +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 20),
    axis.title.x = element_text(face = "bold", size = 15),
    axis.title.y = element_text(face = "bold", size = 15),
    axis.text = element_text(size = 12)
  )
```

```{r}
preds_final <- preds_final %>% na.omit()

# Calculate additional metrics for NDVI predictions
r_squared <- cor(preds_final$observed_ndvi, preds_final$preds)^2
mae <- mean(abs(preds_final$observed_ndvi - preds_final$preds))
rmse <- sqrt(mean((preds_final$observed_ndvi - preds_final$preds)^2))
rrmse <- rmse / mean(preds_final$observed_ndvi) * 100
kge <- 1 - sqrt((r_squared - 1)^2 + (mean(preds_final$preds) / mean(preds_final$observed_ndvi) - 1)^2)

# Scatter plot for observed vs. predicted NDVI with metrics
ggplot(preds_final, aes(x = observed_ndvi, y = preds)) +
  geom_point(shape = 21, color = "grey", fill = "forestgreen", alpha = 0.5, size = 3) +
  geom_abline(slope = 1, intercept = 0, color = "black", size = 1) + # 1:1 line
  xlim(0, 1) +
  ylim(0, 1) +
  theme_bw() +
  labs(x = "Observed NDVI", y = "Predicted NDVI") +
  # Add metrics as text
  annotate("text", x = 0.05, y = 1, 
           label = paste0(
             "R²: ", round(r_squared, 3), "\n",
             "MAE: ", round(mae, 3), "\n",
             "RMSE: ", round(rmse, 3), "\n",
             "RRMSE: ", round(rrmse, 1), "%\n",
             "KGE: ", round(kge, 3)
           ), hjust = 0, vjust = 1) +
  theme(aspect.ratio = 1, text = element_text(size = 18))
```





















